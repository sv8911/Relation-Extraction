{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ce6ba4c-78fa-4950-bf5c-7881285e1585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded test embeddings from bert_embeddings\\X_test.npy\n",
      "Loaded label binarizer from bert_embeddings\\mlb.pkl\n",
      "Loaded XGBoost model from XGB_model_and_embeddings\\xgb_multi.pkl\n",
      "Loaded optimal thresholds from XGB_model_and_embeddings\\optimal_thresholds.npy\n",
      "Loaded test data from test_revised.json\n",
      "Loaded relation mapping from 'rel_info.json'\n"
     ]
    }
   ],
   "source": [
    "# ------------------- Imports -------------------\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "import pickle\n",
    "import os\n",
    "from itertools import product\n",
    "\n",
    "# ------------------- Load All Necessary Files -------------------\n",
    "embedding_directory = \"bert_embeddings\"\n",
    "model_directory = \"XGB_model_and_embeddings\"\n",
    "\n",
    "test_embedding_path = os.path.join(embedding_directory, \"X_test.npy\")\n",
    "mlb_path = os.path.join(embedding_directory, \"mlb.pkl\")\n",
    "model_path = os.path.join(model_directory, \"xgb_multi.pkl\")\n",
    "thresholds_path = os.path.join(model_directory, \"optimal_thresholds.npy\")\n",
    "test_data_path = \"test_revised.json\"\n",
    "\n",
    "# Load test embeddings\n",
    "test_embeddings = np.load(test_embedding_path)\n",
    "print(f\"Loaded test embeddings from {test_embedding_path}\")\n",
    "\n",
    "# Load MultiLabelBinarizer\n",
    "with open(mlb_path, 'rb') as file:\n",
    "    label_binarizer = pickle.load(file)\n",
    "print(f\"Loaded label binarizer from {mlb_path}\")\n",
    "\n",
    "# Load trained XGBoost model\n",
    "with open(model_path, 'rb') as file:\n",
    "    xgboost_model = pickle.load(file)\n",
    "print(f\"Loaded XGBoost model from {model_path}\")\n",
    "\n",
    "# Load optimal thresholds\n",
    "optimal_thresholds = np.load(thresholds_path)\n",
    "print(f\"Loaded optimal thresholds from {thresholds_path}\")\n",
    "\n",
    "# Load test data\n",
    "with open(test_data_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    test_data = json.load(file)\n",
    "print(f\"Loaded test data from {test_data_path}\")\n",
    "\n",
    "# ------------------- Load Relation Mapping -------------------\n",
    "def load_relation_mapping(file_path=\"rel_info.json\"):\n",
    "    \"\"\"Load relation mapping from JSON file.\"\"\"\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        return json.load(file)\n",
    "\n",
    "relation_mapping = load_relation_mapping()\n",
    "print(\"Loaded relation mapping from 'rel_info.json'\")\n",
    "\n",
    "# ------------------- Real-Time Inference Confidence Filtering -------------------\n",
    "def infer_sample(model, sample_data, sample_embedding, optimal_thresholds, label_binarizer, relation_map, user_sentence):\n",
    "    \"\"\"Perform inference, limiting each entity pair to its top 2 highest-confidence relations.\"\"\"\n",
    "    sentence = user_sentence.strip()\n",
    "\n",
    "    # Extract true triplets and relations from the full sample\n",
    "    true_triplets = [(rel[\"h\"], rel[\"r\"], rel[\"t\"]) for rel in sample_data.get(\"labels\", [])]\n",
    "    true_relations = set(rel[\"r\"] for rel in sample_data.get(\"labels\", []))\n",
    "\n",
    "    # Map entity indices to names from vertexSet\n",
    "    vertex_set = sample_data.get(\"vertexSet\", [])\n",
    "    if vertex_set and isinstance(vertex_set[0], list) and vertex_set[0] and isinstance(vertex_set[0][0], dict):\n",
    "        entities = {i: sublist[0][\"name\"] for i, sublist in enumerate(vertex_set) if sublist}\n",
    "    else:\n",
    "        entities = {}\n",
    "        print(\"Warning: vertexSet missing or malformed. Using indices instead.\")\n",
    "\n",
    "    # Map true triplets to entity names\n",
    "    true_triplets_mapped = [(entities.get(head, str(head)), relation_map.get(rel, rel), entities.get(tail, str(tail)))\n",
    "                            for head, rel, tail in true_triplets]\n",
    "\n",
    "    # Check if an entity appears in the sentence with word boundaries\n",
    "    def entity_in_sentence(entity, sentence):\n",
    "        return re.search(r'\\b' + re.escape(entity) + r'\\b', sentence, re.IGNORECASE) is not None\n",
    "\n",
    "    # Filter true triplets to those with head and tail in the user sentence\n",
    "    true_triplets_filtered = [triplet for triplet in true_triplets_mapped\n",
    "                              if entity_in_sentence(triplet[0], sentence) and entity_in_sentence(triplet[2], sentence)]\n",
    "\n",
    "    # Identify entities present in the user sentence\n",
    "    sentence_entities = [entity for idx, entity in entities.items() if entity_in_sentence(entity, sentence)]\n",
    "\n",
    "    # Prepare input for XGBoost\n",
    "    sample_embedding = sample_embedding.reshape(1, -1)  # Ensure shape is [1, 768]\n",
    "\n",
    "    # Predict relation probabilities\n",
    "    probability_raw = model.predict_proba(sample_embedding)\n",
    "    probability_scores = np.array([prob[:, 1] for prob in probability_raw]).T[0]  # Shape: [n_classes]\n",
    "\n",
    "    # Filter to top 5 highest-confidence relations with their scores\n",
    "    relation_probabilities = [(label_binarizer.classes_[idx], prob) for idx, prob in enumerate(probability_scores)\n",
    "                              if prob >= optimal_thresholds[idx]]\n",
    "    top_relation_probabilities = sorted(relation_probabilities, key=lambda x: x[1], reverse=True)[:5]\n",
    "    top_relations_with_scores = {rel: prob for rel, prob in top_relation_probabilities}\n",
    "\n",
    "    # Generate triplets, limiting each entity pair to its highest-confidence relations\n",
    "    predicted_triplets = []\n",
    "    for head, tail in product(sentence_entities, repeat=2):\n",
    "        if head != tail:  # Exclude self-relations\n",
    "            sorted_relations = sorted(top_relations_with_scores.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "            for relation, _ in sorted_relations:\n",
    "                mapped_relation = relation_map.get(relation, relation)\n",
    "                predicted_triplets.append((head, mapped_relation, tail))\n",
    "\n",
    "    # Filter predicted triplets to only those matching true triplets\n",
    "    true_triplets_set = set(true_triplets_filtered)\n",
    "    matched_predicted_triplets = [triplet for triplet in predicted_triplets if triplet in true_triplets_set]\n",
    "\n",
    "    # Calculate match count\n",
    "    correct_triplets = len(matched_predicted_triplets)\n",
    "    total_true_triplets = len(true_triplets_set)\n",
    "    total_predicted_triplets = len(set(predicted_triplets))\n",
    "\n",
    "    return {\n",
    "        \"sentence\": sentence,\n",
    "        \"true_triplets\": list(true_triplets_filtered),\n",
    "        \"predicted_triplets\": matched_predicted_triplets,\n",
    "        \"match_count\": (correct_triplets, total_true_triplets, total_predicted_triplets)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25c69a98-b889-45df-b110-b81912a2bd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Test Samples (First 3 Sentences)\n",
      "Sample 1: \"Antony Noghès ( 13 September 1890 in Monaco – 2 August 1978 in Monte Carlo , Monaco ) was the founder of the Monaco Grand Prix . He also helped create the Rallye Monte - Carlo in 1911 . He suggested the international adoption of the checkered flag to end races . ...\"\n",
      "\n",
      "Sample 2: \"I , Frankenstein is a 2014 Australian - American action - horror film written and directed by Stuart Beattie , based on the digital - only graphic novel by Kevin Grevioux . The film was produced by Tom Rosenberg , Gary Lucchesi , Richard Wright , Andrew Mason and Sidney Kimmel . It stars Aaron Eckhart , Bill Nighy , Yvonne Strahovski , Miranda Otto and Jai Courtney . ...\"\n",
      "\n",
      "Sample 3: \"Resident Evil : Degeneration , known in Japan as , is a biopunk action horror film directed by Makoto Kamiya . It is the first full - length motion capture CG animation feature in Capcom 's Resident Evil franchise . The film was made by Capcom Studios in cooperation with Sony Pictures Entertainment . ...\"\n",
      "\n",
      "Sample 4: \"Arcadia were a new wave British group formed in 1985 by Simon Le Bon , Nick Rhodes , and Roger Taylor of Duran Duran as a side project during a break in that band 's schedule . The project was only active during 1985 and 1986 for just one album , So Red the Rose , which was certified Platinum in the United States and included the singles \" Election Day \" , \" Goodbye Is Forever \" , \" The Flame \" and \" The Promise ( ft . David Gilmour and Sting ) \" . ...\"\n",
      "\n",
      "Sample 5: \"Life in Color is a United States - based EDM event company , best known for their ongoing \" paint party \" Life in Color concert tours . The company was founded by Sebastian Solano , Paul Campbell , Lukasz Tracz and Patryk Tracz as Committee Entertainment and the concert tour Dayglow in 2006 . Billed by its organizers as the \" world 's largest paint party \" , the tour features performances by electronic musicians , joined by artistic performers and the tour 's signature spraying of the audience with paint throughout the show . ...\"\n",
      "\n",
      "Sample 6: \"Street Fighter X Mega Man , also known as in Japan , is a crossover platform game created by Singaporean fan developer Seow Zong Hui . Initially developed as a fan game , Street Fighter X Mega Man later received support from Capcom , who assisted in the production of the game . Street Fighter X Mega Man was released as a free download from Capcom Unity on December 17 , 2012 . ...\"\n",
      "\n",
      "Sample 7: \"\" The Murders in the Rue Morgue \" is a short story by Edgar Allan Poe published in Graham 's Magazine in 1841 . It has been recognized as the first modern detective story ; Poe referred to it as one of his \" tales of ratiocination \" . C. ...\"\n",
      "\n",
      "Sample 8: \"Joseph Alexander Cooper ( November 25 , 1823 – May 20 , 1910 ) was an American farmer , soldier , and civil servant . A Southern Unionist , he fought for the Union Army during the American Civil War , commanding units at Mill Springs , Stones River , Chickamauga , Franklin , Nashville , Bentonville , and in the Knoxville and Atlanta campaigns . He had achieved the rank of Brevet Major General by the time he was mustered out in early 1866 . ...\"\n",
      "\n",
      "Sample 9: \"The Neue Bachgesellschaft , or New Bach Society , is an organisation based in Leipzig , Germany , devoted to the music of the composer Johann Sebastian Bach . It was founded in 1900 as the successor to the Bach Gesellschaft , which between 1850 and 1900 produced a complete edition of Bach 's works , publishing many pieces for the first time . On completion of these collected works ( the Bach - Ausgabe ) , the original Society dissolved itself . ...\"\n",
      "\n",
      "Sample 10: \"\" All Together Now \" is a song by Liverpudlian band The Farm from their album Spartacus , and links some of the band 's favourite themes : socialism , brotherhood and football . Peter Hooton wrote the lyrics in his early 20s after reading about the Christmas truce of 1914 . The song was first recorded under the title \" No Man 's Land \" for a John Peel session in 1983 . ...\"\n",
      "\n",
      "Sample 11: \"Grant Green Jr. ( né Gregory Green ) is a jazz guitarist and son of jazz guitar player Grant Green . He is a member of the group Masters of Groove , along with drummer Bernard Purdie and B3 organ player Reuben Wilson . ...\"\n",
      "\n",
      "Sample 12: \"John Dacher McWilliams ( July 23 , 1891 – March 30 , 1975 ) was a U.S. Representative from Connecticut . He was born in Norwich , Connecticut to Elizabeth A. ...\"\n",
      "\n",
      "Sample 13: \"Piracy on Falcon Lake refers to an increase in crime at the border between the United States and Mexico on Falcon Lake . The lake is a long reservoir of the Rio Grande that was constructed in 1954 and is a known drug smuggling route . A turf war between rival drug cartels for control of the lake began in March 2010 and has led to a series of armed robberies and shooting incidents . ...\"\n",
      "\n",
      "Sample 14: \"Suikerbosrand Nature Reserve is a protected area in the Suikerbosrand Range , South Africa . It is one of Gauteng ’s premier ecotourism destinations . Set just a short distance from Johannesburg , an hour 's drive from Johannesburg International Airport and near the historical town of Heidelberg , this reserve boasts a representative sample of the fauna and flora of the rocky Highveld grassland biome . ...\"\n",
      "\n",
      "Sample 15: \"Alan Belford Jones AO ( born 13 April 1941 , or possibly 1942 or 1943 ) is an Australian radio broadcaster . He is a former coach of the Australia national rugby union team and rugby league coach and administrator . He has worked as a school teacher , a speech writer in the office of the Prime Minister Malcolm Fraser , and in musical theatre . ...\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Interactive Inference\n",
      "--------------------------------------------------\n",
      "Instructions:\n",
      "  The samples listed above are randomly selected from 'test_revised.json'.\n",
      "  Please enter a partial or full sentence from any of the 15 samples displayed.\n",
      "  Example: 'The Sims class destroyers were built'\n",
      "  To exit, type 'exit'.\n",
      "  Output will show true triplets and matching predicted triplets.\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter sentence part (or 'exit'):  Antony Noghès ( 13 September 1890 in Monaco – 2 August 1978 in Monte Carlo , Monaco ) was the founder of the Monaco Grand Prix . He also helped create the Rallye Monte - Carlo in 1911 .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input Sentence:\n",
      "  \"Antony Noghès ( 13 September 1890 in Monaco – 2 August 1978 in Monte Carlo , Monaco ) was the founder of the Monaco Grand Prix . He also helped create the Rallye Monte - Carlo in 1911 .\"\n",
      "True Triplets:\n",
      "  (Antony Noghès, place of death, Monte Carlo)\n",
      "  (Antony Noghès, date of birth, 13 September 1890)\n",
      "  (Antony Noghès, date of death, 2 August 1978)\n",
      "  (Monte Carlo, country, Monaco)\n",
      "  (Rallye Monte - Carlo, country, Monaco)\n",
      "  (Rallye Monte - Carlo, inception, 1911)\n",
      "  (Antony Noghès, country of citizenship, Monaco)\n",
      "  (Monaco Grand Prix, founded by, Antony Noghès)\n",
      "  (Antony Noghès, place of death, Monaco)\n",
      "  (Antony Noghès, place of birth, Monaco)\n",
      "  (Monaco Grand Prix, country, Monaco)\n",
      "  (Monaco Grand Prix, location, Monaco)\n",
      "  (Monte Carlo, located in the administrative territorial entity, Monaco)\n",
      "Predicted Triplets (Matching True Triplets):\n",
      "  (Antony Noghès, date of birth, 13 September 1890)\n",
      "  (Antony Noghès, country of citizenship, Monaco)\n",
      "  (Monte Carlo, country, Monaco)\n",
      "  (Monaco Grand Prix, country, Monaco)\n",
      "  (Rallye Monte - Carlo, country, Monaco)\n",
      "Match Count: 5/13 true triplets correctly predicted \n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter sentence part (or 'exit'):  exit\n"
     ]
    }
   ],
   "source": [
    "# ------------------- Display 15 Random Test Samples -------------------\n",
    "print(\"\\nRandom Test Samples (First 3 Sentences)\")\n",
    "random_samples = random.sample(list(enumerate(test_data)), min(15, len(test_data)))\n",
    "sample_indices = [idx for idx, _ in random_samples]\n",
    "sample_sentences = {idx: \" \".join([\" \".join(sent) for sent in test_data[idx].get(\"sents\", [])]).strip()\n",
    "                    for idx, _ in random_samples}\n",
    "\n",
    "for i, (idx, sentence) in enumerate(sample_sentences.items(), 1):\n",
    "    sentences = sentence.split(\". \")\n",
    "    display_text = \". \".join(sentences[:3]) + (\".\" if len(sentences) >= 3 else \"\")\n",
    "    if len(sentences) > 3:\n",
    "        display_text += \" ...\"\n",
    "    print(f\"Sample {i}: \\\"{display_text}\\\"\")\n",
    "    print()\n",
    "\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# ------------------- Interactive Inference Section -------------------\n",
    "print(\"\\nInteractive Inference\")\n",
    "print(\"-\" * 50)\n",
    "print(\"Instructions:\")\n",
    "print(\"  The samples listed above are randomly selected from 'test_revised.json'.\")\n",
    "print(\"  Please enter a partial or full sentence from any of the 15 samples displayed.\")\n",
    "print(\"  Example: 'The Sims class destroyers were built'\")\n",
    "print(\"  To exit, type 'exit'.\")\n",
    "print(\"  Output will show true triplets and matching predicted triplets.\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"Enter sentence part (or 'exit'): \").strip()\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    matched_index = None\n",
    "    for idx, sentence in sample_sentences.items():\n",
    "        if user_input.lower() in sentence.lower():\n",
    "            matched_index = idx\n",
    "            break\n",
    "\n",
    "    if matched_index is not None:\n",
    "        sample_data = test_data[matched_index]\n",
    "        sample_embedding = test_embeddings[matched_index]\n",
    "        result = infer_sample(xgboost_model, sample_data, sample_embedding, optimal_thresholds, \n",
    "                             label_binarizer, relation_mapping, user_input)\n",
    "\n",
    "        print(\"\\nInput Sentence:\")\n",
    "        print(f\"  \\\"{result['sentence']}\\\"\")\n",
    "        print(\"True Triplets:\")\n",
    "        for head, relation, tail in result['true_triplets']:\n",
    "            print(f\"  ({head}, {relation}, {tail})\")\n",
    "        print(\"Predicted Triplets (Matching True Triplets):\")\n",
    "        if result['predicted_triplets']:\n",
    "            for head, relation, tail in result['predicted_triplets']:\n",
    "                print(f\"  ({head}, {relation}, {tail})\")\n",
    "        else:\n",
    "            print(\"  No matching triplets predicted.\")\n",
    "        print(f\"Match Count: {result['match_count'][0]}/{result['match_count'][1]} true triplets correctly predicted \")\n",
    "    else:\n",
    "        print(\"\\nNo match found. Please enter a part of a sentence from the list above.\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee978da-fe97-4a3e-b6c5-a84214e3c62b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145250cc-0718-4eec-8e76-d5c43f155ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
